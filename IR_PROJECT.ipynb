{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc42c1d-3330-43c0-8c34-1eba52953dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information Retrieval System with Boolean Retrieval and Evaluation\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import defaultdict\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load dataset (make sure the CSV file exists in the project directory)\n",
    "file_path = 'Online_Retail_UTF8.csv'\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "text_column = 'Description'\n",
    "id_column = 'InvoiceNo'\n",
    "\n",
    "# Initialize stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Tokenization and stemming function\n",
    "def tokenize_and_stem(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return list(set(stemmed_tokens))  # Remove duplicates\n",
    "\n",
    "# Apply preprocessing\n",
    "df['Tokenized_And_Stemmed_Text'] = df[text_column].apply(lambda x: tokenize_and_stem(str(x)))\n",
    "\n",
    "# Preview first 5 documents\n",
    "for i, tokens in enumerate(df['Tokenized_And_Stemmed_Text'].head(5)):\n",
    "    print(f\"Document {i+1} tokens (deduplicated and normalized): {tokens}\\n\")\n",
    "\n",
    "# Build inverted index from first 20 documents\n",
    "inverted_index = defaultdict(list)\n",
    "\n",
    "for doc_id, tokens in enumerate(df['Tokenized_And_Stemmed_Text'].head(20)):\n",
    "    for token in tokens:\n",
    "        inverted_index[token].append(doc_id + 1)\n",
    "\n",
    "# Display inverted index\n",
    "print(\"Inverted Index for the first 20 documents:\")\n",
    "for term, doc_ids in inverted_index.items():\n",
    "    print(f\"Term: '{term}' appears in documents: {doc_ids}\")\n",
    "\n",
    "# Boolean retrieval model\n",
    "def boolean_retrieval(query, inverted_index):\n",
    "    query_terms = [stemmer.stem(token) for token in word_tokenize(query)]\n",
    "    result_set = set(inverted_index[query_terms[0]]) if query_terms[0] in inverted_index else set()\n",
    "\n",
    "    i = 1\n",
    "    while i < len(query_terms):\n",
    "        operator = query_terms[i].upper()\n",
    "        next_term = query_terms[i + 1] if (i + 1) < len(query_terms) else None\n",
    "        if not next_term:\n",
    "            break\n",
    "        next_term = stemmer.stem(next_term)\n",
    "        next_term_set = set(inverted_index[next_term]) if next_term in inverted_index else set()\n",
    "\n",
    "        if operator == \"AND\":\n",
    "            result_set &= next_term_set\n",
    "        elif operator == \"OR\":\n",
    "            result_set |= next_term_set\n",
    "        elif operator == \"NOT\":\n",
    "            result_set -= next_term_set\n",
    "        i += 2\n",
    "    return sorted(list(result_set))\n",
    "\n",
    "# Precision and recall calculation\n",
    "def calculate_precision_recall(query, relevant_docs, inverted_index):\n",
    "    retrieved_docs = boolean_retrieval(query, inverted_index)\n",
    "    true_positives = len(set(retrieved_docs) & set(relevant_docs))\n",
    "    false_positives = len(set(retrieved_docs) - set(relevant_docs))\n",
    "    false_negatives = len(set(relevant_docs) - set(retrieved_docs))\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "# Define relevant documents for evaluation (update this based on actual data)\n",
    "relevant_docs = list(range(1, 21))\n",
    "\n",
    "# Prompt query input and run evaluation\n",
    "query = input(\"Please enter your search query (use AND, OR, NOT): \")\n",
    "result_documents = boolean_retrieval(query, inverted_index)\n",
    "precision, recall = calculate_precision_recall(query, relevant_docs, inverted_index)\n",
    "\n",
    "# Display result documents and metrics\n",
    "if result_documents:\n",
    "    print(f\"Documents matching the query '{query}':\")\n",
    "    for doc_id in result_documents:\n",
    "        doc_title = df[text_column].iloc[doc_id - 1]\n",
    "        print(f\"Document ID: {doc_id} , Title/Description: {doc_title}\")\n",
    "else:\n",
    "    print(f\"No documents match the query '{query}'.\")\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a84557-c01e-4711-abf3-0daaf9970068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
